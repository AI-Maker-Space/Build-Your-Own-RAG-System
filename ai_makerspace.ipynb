{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aimakerspace.text_utils import TextFileLoader, CharacterTextSplitter\n",
    "from aimakerspace.vectordatabase import VectorDatabase\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_loader = TextFileLoader(\"data/KingLear.txt\")\n",
    "documents = text_loader.load_documents()\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter()\n",
    "split_documents = text_splitter.split_texts(documents)\n",
    "len(split_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db = VectorDatabase()\n",
    "vector_db = asyncio.run(vector_db.abuild_from_list(split_documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\". The same-\\n     Your servant Kent. Where is your servant Caius?\\n  Lear. He's a good fellow, I can tell you that.\\n     He'll strike, and quickly too. He's dead and rotten.\\n  Kent. No, my good lord; I am the very man-\\n  Lear. I'll see that straight.\\n  Kent. That from your first of difference and decay\\n     Have followed your sad steps.\\n  Lear. You're welcome hither.\\n  Kent. Nor no man else! All's cheerless, dark, and deadly.\\n     Your eldest daughters have fordone themselves,\\n     And desperately are dead.\\n  Lear. Ay, so I think.\\n  Alb. He knows not what he says; and vain is it\\n     That we present us to him.\\n  Edg. Very bootless.\\n\\n                           Enter a Captain. \\n\\n  Capt. Edmund is dead, my lord.\\n  Alb. That's but a trifle here.\\n     You lords and noble friends, know our intent.\\n     What comfort to this great decay may come\\n     Shall be applied. For us, we will resign,\\n     During the life of this old Majesty,\\n     To him our absolute power; [to Edgar and Kent] you to you\",\n",
       "  0.8648614387390735),\n",
       " (\"\\n  Kent. O my good master!\\n  Lear. Prithee away!\\n  Edg. 'Tis noble Kent, your friend.\\n  Lear. A plague upon you, murderers, traitors all!\\n     I might have sav'd her; now she's gone for ever!\\n     Cordelia, Cordelia! stay a little. Ha!\\n     What is't thou say'st, Her voice was ever soft,\\n     Gentle, and low- an excellent thing in woman.\\n     I kill'd the slave that was a-hanging thee.\\n  Capt. 'Tis true, my lords, he did.\\n  Lear. Did I not, fellow?\\n     I have seen the day, with my good biting falchion\\n     I would have made them skip. I am old now,\\n     And these same crosses spoil me. Who are you?\\n     Mine eyes are not o' th' best. I'll tell you straight.\\n  Kent. If fortune brag of two she lov'd and hated, \\n     One of them we behold.\\n  Lear. This' a dull sight. Are you not Kent?\\n  Kent. The same-\\n     Your servant Kent. Where is your servant Caius?\\n  Lear. He's a good fellow, I can tell you that.\\n     He'll strike, and quickly too. He's dead and rotten.\\n  Kent. No, my good lord; I \",\n",
       "  0.8427105336022884),\n",
       " (\"    Exeunt.\\n\\n\\n\\n\\nScene IV.\\nThe Duke of Albany's Palace.\\n\\nEnter Kent, [disguised].\\n\\n  Kent. If but as well I other accents borrow,\\n     That can my speech defuse, my good intent\\n     May carry through itself to that full issue\\n     For which I raz'd my likeness. Now, banish'd Kent,\\n     If thou canst serve where thou dost stand condemn'd,\\n     So may it come, thy master, whom thou lov'st,\\n     Shall find thee full of labours.\\n\\n         Horns within. Enter Lear, [Knights,] and Attendants.\\n\\n  Lear. Let me not stay a jot for dinner; go get it ready. [Exit\\n     an Attendant.] How now? What art thou?\\n  Kent. A man, sir.\\n  Lear. What dost thou profess? What wouldst thou with us?\\n  Kent. I do profess to be no less than I seem, to serve him\\ntruly\\n     that will put me in trust, to love him that is honest, to\\n     converse with him that is wise and says little, to fear \\n     judgment, to fight when I cannot choose, and to eat no fish.\\n  Lear. What art thou?\\n  Kent. A very honest-hearted fellow, a\",\n",
       "  0.8232578473832918)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_db.search_by_text(\"Your servant Kent. Where is your servant Caius?\", k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aimakerspace.openai_utils.prompts import (\n",
    "    UserRolePrompt,\n",
    "    SystemRolePrompt,\n",
    "    AssistantRolePrompt,\n",
    ")\n",
    "\n",
    "from aimakerspace.openai_utils.chatmodel import ChatOpenAI\n",
    "\n",
    "chat_openai = ChatOpenAI()\n",
    "user_prompt_template = \"{content}\"\n",
    "user_role_prompt = UserRolePrompt(user_prompt_template)\n",
    "system_prompt_template = (\n",
    "    \"You are an expert in {expertise}, you always answer in a kind way.\"\n",
    ")\n",
    "system_role_prompt = SystemRolePrompt(system_prompt_template)\n",
    "\n",
    "messages = [\n",
    "    user_role_prompt.create_message(\n",
    "        content=\"What is the best way to write a loop?\"\n",
    "    ),\n",
    "    system_role_prompt.create_message(expertise=\"Python\"),\n",
    "]\n",
    "\n",
    "response = chat_openai.run(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAQA_PROMPT_TEMPLATE = \"\"\"\n",
    "Use the provided context to answer the user's query. \n",
    "\n",
    "You may not answer the user's query unless there is specific context in the following text.\n",
    "\n",
    "If you do not know the answer, or cannot answer, please respond with \"I don't know\".\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "raqa_prompt = SystemRolePrompt(RAQA_PROMPT_TEMPLATE)\n",
    "\n",
    "USER_PROMPT_TEMPLATE = \"\"\"\n",
    "User Query:\n",
    "{user_query}\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = UserRolePrompt(USER_PROMPT_TEMPLATE)\n",
    "\n",
    "class RetrievalAugmentedQAPipeline:\n",
    "    def __init__(self, llm: ChatOpenAI(), vector_db_retriever: VectorDatabase) -> None:\n",
    "        self.llm = llm\n",
    "        self.vector_db_retriever = vector_db_retriever\n",
    "\n",
    "    def run_pipeline(self, user_query: str) -> str:\n",
    "        context_list = self.vector_db_retriever.search_by_text(user_query, k=4)\n",
    "        \n",
    "        context_prompt = \"\"\n",
    "        for context in context_list:\n",
    "            context_prompt += context[0] + \"\\n\"\n",
    "\n",
    "        formatted_system_prompt = raqa_prompt.create_message(context=context_prompt)\n",
    "\n",
    "        formatted_user_prompt = user_prompt.create_message(user_query=user_query)\n",
    "        \n",
    "        return self.llm.run([formatted_system_prompt, formatted_user_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_augmented_qa_pipeline = RetrievalAugmentedQAPipeline(\n",
    "    vector_db_retriever=vector_db,\n",
    "    llm=chat_openai\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'King Lear is the main character in William Shakespeare\\'s play, \"King Lear.\" He is the King of Britain and the father of three daughters: Goneril, Regan, and Cordelia. The play focuses on Lear\\'s descent into madness and the consequences of his decision to divide his kingdom between his two elder daughters, who betray and mistreat him.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_augmented_qa_pipeline.run_pipeline(\"Who is King Lear?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_augmented_qa_pipeline.run_pipeline(\"Who is Batman?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Cordelia is seen in the French camp with Kent, the Doctor, and a Gentleman. They discuss Cordelia's feelings towards Kent and her gratitude for his goodness. They mention that Cordelia's life will be too short to repay Kent's goodness. The scene does not provide any specific information about what happens to Cordelia after this moment.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_augmented_qa_pipeline.run_pipeline(\"What happens to Cordelia?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "buildyourownlangchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
